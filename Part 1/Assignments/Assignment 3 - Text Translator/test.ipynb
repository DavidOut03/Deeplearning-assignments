{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'english': ['hello', 'how are you', 'thank you'],\n",
    "    'dutch': ['hallo', 'hoe gaat het', 'dank je wel']\n",
    "}\n",
    "df = pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(texts):\n",
    "    tokenizer = Tokenizer(filters='', lower=True)\n",
    "    tokenizer.fit_on_texts(texts)\n",
    "    sequences = tokenizer.texts_to_sequences(texts)\n",
    "    word_index = tokenizer.word_index\n",
    "    return sequences, word_index, tokenizer\n",
    "\n",
    "input_texts = df['english']\n",
    "target_texts = ['<start> ' + t + ' <end>' for t in df['dutch']]\n",
    "\n",
    "input_seq, input_word_index, input_tokenizer = tokenize(input_texts)\n",
    "target_seq, target_word_index, target_tokenizer = tokenize(target_texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_encoder_seq_length = max(len(seq) for seq in input_seq)\n",
    "max_decoder_seq_length = max(len(seq) for seq in target_seq)\n",
    "\n",
    "encoder_input_data = pad_sequences(input_seq, maxlen=max_encoder_seq_length, padding='post')\n",
    "decoder_input_data = pad_sequences([seq[:-1] for seq in target_seq], maxlen=max_decoder_seq_length-1, padding='post')\n",
    "decoder_target_data = pad_sequences([seq[1:] for seq in target_seq], maxlen=max_decoder_seq_length-1, padding='post')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " encoder_input (InputLayer)     [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " decoder_input (InputLayer)     [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " encoder_embedding (Embedding)  (None, None, 64)     384         ['encoder_input[0][0]']          \n",
      "                                                                                                  \n",
      " decoder_embedding (Embedding)  (None, None, 64)     640         ['decoder_input[0][0]']          \n",
      "                                                                                                  \n",
      " encoder_lstm (LSTM)            [(None, 64),         33024       ['encoder_embedding[0][0]']      \n",
      "                                 (None, 64),                                                      \n",
      "                                 (None, 64)]                                                      \n",
      "                                                                                                  \n",
      " decoder_lstm (LSTM)            [(None, None, 64),   33024       ['decoder_embedding[0][0]',      \n",
      "                                 (None, 64),                      'encoder_lstm[0][1]',           \n",
      "                                 (None, 64)]                      'encoder_lstm[0][2]']           \n",
      "                                                                                                  \n",
      " decoder_dense (Dense)          (None, None, 10)     650         ['decoder_lstm[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 67,722\n",
      "Trainable params: 67,722\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 64\n",
    "lstm_units = 64\n",
    "\n",
    "# Encoder\n",
    "encoder_inputs = Input(shape=(None,), name=\"encoder_input\")\n",
    "encoder_embedding_layer = Embedding(len(input_word_index) + 1, embedding_dim, name=\"encoder_embedding\")\n",
    "enc_emb = encoder_embedding_layer(encoder_inputs)\n",
    "encoder_lstm = LSTM(lstm_units, return_state=True, name=\"encoder_lstm\")\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(enc_emb)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Decoder\n",
    "decoder_inputs = Input(shape=(None,), name=\"decoder_input\")\n",
    "decoder_embedding_layer = Embedding(len(target_word_index) + 1, embedding_dim, name=\"decoder_embedding\")\n",
    "dec_emb = decoder_embedding_layer(decoder_inputs)\n",
    "decoder_lstm = LSTM(lstm_units, return_sequences=True, return_state=True, name=\"decoder_lstm\")\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=encoder_states)\n",
    "decoder_dense = Dense(len(target_word_index) + 1, activation='softmax', name=\"decoder_dense\")\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Final model\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "2/2 [==============================] - 3s 11ms/step - loss: 2.3025\n",
      "Epoch 2/300\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.2910\n",
      "Epoch 3/300\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.2818\n",
      "Epoch 4/300\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.2728\n",
      "Epoch 5/300\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.2624\n",
      "Epoch 6/300\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.2531\n",
      "Epoch 7/300\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.2416\n",
      "Epoch 8/300\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.2284\n",
      "Epoch 9/300\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.2167\n",
      "Epoch 10/300\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.1993\n",
      "Epoch 11/300\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.1817\n",
      "Epoch 12/300\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.1654\n",
      "Epoch 13/300\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.1386\n",
      "Epoch 14/300\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.1171\n",
      "Epoch 15/300\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.0812\n",
      "Epoch 16/300\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.0524\n",
      "Epoch 17/300\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.0109\n",
      "Epoch 18/300\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.9653\n",
      "Epoch 19/300\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.9097\n",
      "Epoch 20/300\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.8399\n",
      "Epoch 21/300\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.7854\n",
      "Epoch 22/300\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.7149\n",
      "Epoch 23/300\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.6387\n",
      "Epoch 24/300\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.5922\n",
      "Epoch 25/300\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.5355\n",
      "Epoch 26/300\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.4845\n",
      "Epoch 27/300\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.4436\n",
      "Epoch 28/300\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.4025\n",
      "Epoch 29/300\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.3591\n",
      "Epoch 30/300\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.3155\n",
      "Epoch 31/300\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.2718\n",
      "Epoch 32/300\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.2285\n",
      "Epoch 33/300\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.1921\n",
      "Epoch 34/300\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m decoder_target_data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(decoder_target_data, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mencoder_input_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder_input_data\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_target_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m300\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[0;32m      9\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\david\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\assignment_3_-_text_translator-DEgrxmxA-py3.10\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\david\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\assignment_3_-_text_translator-DEgrxmxA-py3.10\\lib\\site-packages\\keras\\engine\\training.py:1686\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1684\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m   1685\u001b[0m tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[1;32m-> 1686\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mdata_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshould_sync\u001b[49m:\n\u001b[0;32m   1687\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n\u001b[0;32m   1688\u001b[0m \u001b[38;5;66;03m# No error, now safe to assign to logs.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\david\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\assignment_3_-_text_translator-DEgrxmxA-py3.10\\lib\\site-packages\\keras\\engine\\data_adapter.py:1415\u001b[0m, in \u001b[0;36mDataHandler.should_sync\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1402\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"The inferred steps per epoch of the created `Dataset`.\u001b[39;00m\n\u001b[0;32m   1403\u001b[0m \n\u001b[0;32m   1404\u001b[0m \u001b[38;5;124;03m    This will be `None` in the case where:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1411\u001b[0m \u001b[38;5;124;03m      The inferred steps per epoch of the created `Dataset`.\u001b[39;00m\n\u001b[0;32m   1412\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   1413\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_steps\n\u001b[1;32m-> 1415\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m   1416\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mshould_sync\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1417\u001b[0m     \u001b[38;5;66;03m# Catch OutOfRangeError for Datasets of unknown size.\u001b[39;00m\n\u001b[0;32m   1418\u001b[0m     \u001b[38;5;66;03m# This blocks until the batch has finished executing.\u001b[39;00m\n\u001b[0;32m   1419\u001b[0m     \u001b[38;5;66;03m# TODO(b/150292341): Allow multiple async steps here.\u001b[39;00m\n\u001b[0;32m   1420\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1422\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_log_indefinite_training_warning\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "decoder_target_data = np.expand_dims(decoder_target_data, -1)\n",
    "\n",
    "model.fit(\n",
    "    [encoder_input_data, decoder_input_data],\n",
    "    decoder_target_data,\n",
    "    batch_size=2,\n",
    "    epochs=300,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model = Model(encoder_inputs, encoder_states)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference decoder inputs\n",
    "decoder_state_input_h = Input(shape=(lstm_units,))\n",
    "decoder_state_input_c = Input(shape=(lstm_units,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "\n",
    "# Reuse decoder embedding layer\n",
    "dec_emb2 = decoder_embedding_layer(decoder_inputs)\n",
    "\n",
    "# Reuse decoder LSTM and Dense\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_states_inputs)\n",
    "decoder_outputs2 = decoder_dense(decoder_outputs2)\n",
    "decoder_states2 = [state_h2, state_c2]\n",
    "\n",
    "# Inference model\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs2] + decoder_states2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    target_seq = np.zeros((1, 1))\n",
    "    target_seq[0, 0] = target_word_index['<start>']  # Or 'start' if that's your token\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = []\n",
    "\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_word = [word for word, index in target_word_index.items() if index == sampled_token_index][0]\n",
    "\n",
    "        if sampled_word == '<end>' or len(decoded_sentence) > max_decoder_seq_length:\n",
    "            stop_condition = True\n",
    "        else:\n",
    "            decoded_sentence.append(sampled_word)\n",
    "\n",
    "        target_seq = np.zeros((1, 1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return ' '.join(decoded_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "English: how are you\n",
      "Dutch: hoe gaat het\n"
     ]
    }
   ],
   "source": [
    "def encode_input_text(text):\n",
    "    seq = input_tokenizer.texts_to_sequences([text])\n",
    "    padded = pad_sequences(seq, maxlen=max_encoder_seq_length, padding='post')\n",
    "    return padded\n",
    "\n",
    "test_sentence = \"how are you\"\n",
    "input_seq = encode_input_text(test_sentence)\n",
    "translated = decode_sequence(input_seq)\n",
    "print(\"English:\", test_sentence)\n",
    "print(\"Dutch:\", translated)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://chatgpt.com/c/67e80ee8-8914-8009-b378-b9afa7150bde"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "assignment_3_-_text_translator-DEgrxmxA-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
